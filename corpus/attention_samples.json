{
  "python_doctest": [
    {
      "id": "py_simple_add",
      "code": "def add(a, b):\n    \"\"\"\n    >>> add(2, 3)\n    5\n    \"\"\"\n    return a + b",
      "doctest_token_pos": 9,
      "function_param_positions": [1, 2, 4, 10]
    },
    {
      "id": "py_long_name",
      "code": "def calculate_fibonacci_sequence(n):\n    \"\"\"\n    >>> calculate_fibonacci_sequence(5)\n    8\n    \"\"\"\n    if n <= 1:\n        return n\n    return calculate_fibonacci_sequence(n-1) + calculate_fibonacci_sequence(n-2)",
      "doctest_token_pos": 11,
      "function_param_positions": [1, 2, 3, 4, 5, 6, 12]
    },
    {
      "id": "py_multi_param",
      "code": "def merge_sorted_arrays(arr1, arr2, arr3):\n    \"\"\"\n    >>> merge_sorted_arrays([1], [2], [3])\n    [1, 2, 3]\n    \"\"\"\n    return sorted(arr1 + arr2 + arr3)",
      "doctest_token_pos": 16,
      "function_param_positions": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 17]
    },
    {
      "id": "py_complex_params",
      "code": "def process_data(input_dict, transform_fn, output_format, verbose=True):\n    \"\"\"\n    >>> process_data({'a': 1}, lambda x: x*2, 'json')\n    '{\"a\": 2}'\n    \"\"\"\n    result = {k: transform_fn(v) for k, v in input_dict.items()}\n    return str(result) if output_format == 'json' else result",
      "doctest_token_pos": 18,
      "function_param_positions": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 19]
    },
    {
      "id": "py_single_char_param",
      "code": "def f(x):\n    \"\"\"\n    >>> f(10)\n    100\n    \"\"\"\n    return x * x",
      "doctest_token_pos": 7,
      "function_param_positions": [1, 2, 8]
    },
    {
      "id": "py_multiple_doctests",
      "code": "def divide(numerator, denominator):\n    \"\"\"\n    >>> divide(10, 2)\n    5.0\n    >>> divide(7, 2)\n    3.5\n    \"\"\"\n    return numerator / denominator",
      "doctest_token_pos": 10,
      "function_param_positions": [1, 2, 3, 4, 5, 11]
    },
    {
      "id": "py_list_operations",
      "code": "def filter_even_numbers(numbers):\n    \"\"\"\n    >>> filter_even_numbers([1, 2, 3, 4, 5, 6])\n    [2, 4, 6]\n    \"\"\"\n    return [n for n in numbers if n % 2 == 0]",
      "doctest_token_pos": 9,
      "function_param_positions": [1, 2, 3, 4, 10]
    },
    {
      "id": "py_string_manipulation",
      "code": "def reverse_words(text, separator=' '):\n    \"\"\"\n    >>> reverse_words('hello world')\n    'world hello'\n    \"\"\"\n    return separator.join(text.split(separator)[::-1])",
      "doctest_token_pos": 12,
      "function_param_positions": [1, 2, 3, 4, 5, 13]
    },
    {
      "id": "py_default_args",
      "code": "def create_range(start, end, step=1):\n    \"\"\"\n    >>> create_range(0, 10, 2)\n    [0, 2, 4, 6, 8]\n    \"\"\"\n    return list(range(start, end, step))",
      "doctest_token_pos": 14,
      "function_param_positions": [1, 2, 3, 4, 5, 6, 7, 15]
    },
    {
      "id": "py_nested_structure",
      "code": "def flatten(nested_list):\n    \"\"\"\n    >>> flatten([[1, 2], [3, 4]])\n    [1, 2, 3, 4]\n    \"\"\"\n    return [item for sublist in nested_list for item in sublist]",
      "doctest_token_pos": 9,
      "function_param_positions": [1, 2, 3, 4, 10]
    }
  ],
  "rust_test": [
    {
      "id": "rust_simple_add",
      "code": "fn add(a: i32, b: i32) -> i32 {\n    a + b\n}\n\n#[test]\nfn test_add() {\n    assert_eq!(add(2, 3), 5);\n}",
      "test_attr_token_pos": 25,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_option_return",
      "code": "fn find_first<T: PartialEq>(arr: &[T], target: &T) -> Option<usize> {\n    arr.iter().position(|x| x == target)\n}\n\n#[test]\nfn test_find_first() {\n    assert_eq!(find_first(&[1, 2, 3], &2), Some(1));\n}",
      "test_attr_token_pos": 35,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_should_panic",
      "code": "fn divide(a: i32, b: i32) -> i32 {\n    if b == 0 { panic!(\"division by zero\"); }\n    a / b\n}\n\n#[test]\n#[should_panic]\nfn test_divide_by_zero() {\n    divide(10, 0);\n}",
      "test_attr_token_pos": 39,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_result_type",
      "code": "fn parse_number(s: &str) -> Result<i32, std::num::ParseIntError> {\n    s.parse::<i32>()\n}\n\n#[test]\nfn test_parse_number() {\n    assert!(parse_number(\"42\").is_ok());\n    assert!(parse_number(\"abc\").is_err());\n}",
      "test_attr_token_pos": 32,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_multiple_assertions",
      "code": "fn factorial(n: u64) -> u64 {\n    match n {\n        0 | 1 => 1,\n        _ => n * factorial(n - 1),\n    }\n}\n\n#[test]\nfn test_factorial() {\n    assert_eq!(factorial(0), 1);\n    assert_eq!(factorial(1), 1);\n    assert_eq!(factorial(5), 120);\n}",
      "test_attr_token_pos": 41,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_generic_complex",
      "code": "fn map_values<T, U, F>(vec: Vec<T>, f: F) -> Vec<U>\nwhere\n    F: Fn(T) -> U,\n{\n    vec.into_iter().map(f).collect()\n}\n\n#[test]\nfn test_map_values() {\n    let result = map_values(vec![1, 2, 3], |x| x * 2);\n    assert_eq!(result, vec![2, 4, 6]);\n}",
      "test_attr_token_pos": 45,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_tuple_return",
      "code": "fn min_max(arr: &[i32]) -> (i32, i32) {\n    let min = *arr.iter().min().unwrap();\n    let max = *arr.iter().max().unwrap();\n    (min, max)\n}\n\n#[test]\nfn test_min_max() {\n    assert_eq!(min_max(&[1, 5, 3]), (1, 5));\n}",
      "test_attr_token_pos": 52,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_vec_operations",
      "code": "fn filter_even(numbers: Vec<i32>) -> Vec<i32> {\n    numbers.into_iter().filter(|&n| n % 2 == 0).collect()\n}\n\n#[test]\nfn test_filter_even() {\n    assert_eq!(filter_even(vec![1, 2, 3, 4]), vec![2, 4]);\n}",
      "test_attr_token_pos": 38,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_reference_params",
      "code": "fn concat_strings(s1: &str, s2: &str) -> String {\n    format!(\"{}{}\", s1, s2)\n}\n\n#[test]\nfn test_concat() {\n    assert_eq!(concat_strings(\"hello\", \" world\"), \"hello world\");\n}",
      "test_attr_token_pos": 30,
      "function_token_positions": [0, 1, 2]
    },
    {
      "id": "rust_cfg_test_module",
      "code": "fn is_prime(n: u32) -> bool {\n    if n < 2 { return false; }\n    (2..=(n as f64).sqrt() as u32).all(|i| n % i != 0)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    #[test]\n    fn test_is_prime() {\n        assert!(is_prime(7));\n        assert!(!is_prime(8));\n    }\n}",
      "test_attr_token_pos": 53,
      "function_token_positions": [0, 1, 2]
    }
  ],
  "python_baseline": [
    {
      "id": "py_comment_false_doctest",
      "code": "def add(a, b):\n    # >>> this is just a comment, not a doctest\n    return a + b",
      "marker_token_pos": 8,
      "function_param_positions": [1, 2, 4]
    },
    {
      "id": "py_multiline_comment_marker",
      "code": "def multiply(x, y):\n    # Some explanation:\n    # >>> multiply(2, 3) would return 6\n    # but this isn't a real test\n    return x * y",
      "marker_token_pos": 13,
      "function_param_positions": [1, 2, 4]
    },
    {
      "id": "py_string_literal_marker",
      "code": "def process(data):\n    example = \">>> process([1, 2, 3])\"\n    return [x * 2 for x in data]",
      "marker_token_pos": 8,
      "function_param_positions": [1, 2]
    },
    {
      "id": "py_commented_code",
      "code": "def calculate(n):\n    # Old test (commented out):\n    # >>> calculate(5)\n    # 25\n    return n ** 2",
      "marker_token_pos": 15,
      "function_param_positions": [1, 2]
    },
    {
      "id": "py_malformed_docstring",
      "code": "def transform(value, scale):\n    \"\"\"This function transforms a value\n    Example usage (not a doctest):\n    >>> transform(10, 2)\n    returns 20\n    \"\"\"\n    return value * scale",
      "marker_token_pos": 24,
      "function_param_positions": [1, 2, 4]
    }
  ],
  "rust_baseline": [
    {
      "id": "rust_derive_debug",
      "code": "#[derive(Debug)]\nstruct Point {\n    x: i32,\n    y: i32,\n}\n\nfn create_point(x: i32, y: i32) -> Point {\n    Point { x, y }\n}",
      "marker_token_pos": 0,
      "struct_token_positions": [4, 5, 6]
    },
    {
      "id": "rust_cfg_feature",
      "code": "#[cfg(feature = \"serde\")]\nuse serde::{Serialize, Deserialize};\n\nfn process_data(input: &str) -> String {\n    input.to_uppercase()\n}",
      "marker_token_pos": 0,
      "struct_token_positions": [7, 8, 9]
    },
    {
      "id": "rust_allow_dead_code",
      "code": "#[allow(dead_code)]\nfn unused_helper(a: i32, b: i32) -> i32 {\n    a * b\n}\n\nfn main_function(x: i32) -> i32 {\n    x + 1\n}",
      "marker_token_pos": 0,
      "struct_token_positions": [5, 6, 7]
    },
    {
      "id": "rust_inline_attribute",
      "code": "#[inline]\nfn fast_add(a: u64, b: u64) -> u64 {\n    a + b\n}\n\nfn compute(x: u64, y: u64) -> u64 {\n    fast_add(x, y) * 2\n}",
      "marker_token_pos": 0,
      "struct_token_positions": [3, 4, 5]
    },
    {
      "id": "rust_repr_c",
      "code": "#[repr(C)]\nstruct FFIStruct {\n    count: u32,\n    data: *const u8,\n}\n\nfn create_ffi_struct() -> FFIStruct {\n    FFIStruct { count: 0, data: std::ptr::null() }\n}",
      "marker_token_pos": 0,
      "struct_token_positions": [4, 5, 6]
    }
  ]
}
